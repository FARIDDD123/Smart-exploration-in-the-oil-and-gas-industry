# گزارش کار روزانه  
**تاریخ:** 1404/01/30  
**موضوع:** یادگیری مدیریت داده‌های نامتوازن و تکنیک‌های کالیبراسیون مدل  

---

## فعالیت‌های انجام شده:

### ۱. مطالعه و پیاده‌سازی روش‌های مدیریت داده‌های نامتوازن (Imbalanced Data)
- آشنایی با مفهوم داده‌های نامتوازن و اهمیت آن در مدل‌سازی واقعی.
- مطالعه و پیاده‌سازی تکنیک‌های:
  - Random Undersampling و Random Oversampling.
  - SMOTE (Synthetic Minority Over-sampling Technique).
  - بررسی روش‌های پیشرفته‌تر مانند ADASYN و SMOTE-ENN.
- کار عملی:
  - پیاده‌سازی SMOTE روی دیتاست "Credit Card Fraud Detection".
  - مقایسه عملکرد مدل‌های Random Forest و XGBoost قبل و بعد از اعمال SMOTE.

---

### ۲. یادگیری و پیاده‌سازی تکنیک‌های کالیبراسیون مدل
- مطالعه مفهوم کالیبراسیون پیش‌بینی:
  - اهمیت داشتن پیش‌بینی‌های احتمال‌محور صحیح به جای صرفاً برچسب‌های درست.
- یادگیری تکنیک‌های کالیبراسیون:
  - Platt Scaling (با Logistic Regression).
  - Isotonic Regression.
- کار عملی:
  - استفاده از `CalibratedClassifierCV` در Scikit-learn برای کالیبره کردن خروجی مدل SVM.
  - تحلیل منحنی کالیبراسیون (Calibration Curve) قبل و بعد از تنظیم.

---

### ۳. ارزیابی مدل‌های بهبود یافته
- استفاده از متریک‌های جدید برای ارزیابی داده‌های نامتوازن:
  - AUC-ROC.
  - Precision-Recall Curve.
  - F1-Score و Average Precision.
- تجزیه و تحلیل دقیق ماتریس سردرگمی برای مقایسه اثر Oversampling و Undersampling.

---

## چالش‌های امروز:
- اعمال تکنیک SMOTE در دیتاست‌های بسیار بزرگ باعث افزایش شدید زمان آموزش شد.
- تنظیم صحیح مدل‌های کالیبره شده برای جلوگیری از Overfitting روی داده‌های Validation نیاز به دقت بالایی داشت.

---

## برنامه‌ریزی برای روز بعد:
- شروع یادگیری مبانی دیپ لرنینگ با تمرکز بر مفاهیم پایه‌ای نورون، لایه، و شبکه‌های عصبی مصنوعی (ANN).
- آماده‌سازی محیط کاری TensorFlow و PyTorch برای تمرین پروژه‌های عملی.
- پیاده‌سازی یک شبکه عصبی ساده برای طبقه‌بندی داده‌های MNIST.

---

> **تهیه‌کننده:**  
> شایان منصورنیا
